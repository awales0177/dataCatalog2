{
  "toolkit": {
    "functions": [
      {
        "id": "data_validation_utility",
        "name": "data_validation_utility",
        "displayName": "Data Validation Utility",
        "description": "A comprehensive data validation function that checks data types, formats, and business rules",
        "language": "python",
        "category": "data-processing",
        "tags": [
          "validation",
          "data",
          "utility"
        ],
        "code": "def validate_data(data, schema):\n    # Data validation logic here\n    pass",
        "author": "Data Team",
        "version": "1.0.0",
        "lastUpdated": "2025-08-28T00:01:34.133730",
        "usage": "Import and use for any data validation needs",
        "dependencies": [
          "pydantic",
          "jsonschema"
        ],
        "examples": [
          "data_cleaning",
          "api_validation",
          "database_checks"
        ],
        "parameters": [
          {
            "name": "data",
            "type": "any",
            "description": "The data to be validated against the schema",
            "required": true,
            "example": {
              "name": "John",
              "age": 30
            }
          },
          {
            "name": "schema",
            "type": "dict",
            "description": "The validation schema defining the expected data structure",
            "required": true,
            "example": {
              "type": "object",
              "properties": {
                "name": {
                  "type": "string"
                },
                "age": {
                  "type": "number"
                }
              }
            }
          },
          {
            "name": "strict",
            "type": "boolean",
            "description": "Whether to enforce strict validation rules",
            "required": false,
            "default": false,
            "allowedValues": [
              true,
              false
            ]
          },
          {
            "name": "maxErrors",
            "type": "integer",
            "description": "Maximum number of validation errors to collect before stopping",
            "required": false,
            "default": 10,
            "min": 1,
            "max": 100
          },
          {
            "name": "datetype",
            "type": "string",
            "description": "Type of data to validate - either date or time format",
            "required": true,
            "allowedValues": [
              "date",
              "time"
            ],
            "default": "date",
            "example": "date"
          }
        ],
        "git": "https://github.com/example/data-validation-utility",
        "rating": 4.8,
        "downloads": 156
      },
      {
        "id": "api_rate_limiter",
        "name": "api_rate_limiter",
        "displayName": "API Rate Limiter",
        "description": "Efficient rate limiting implementation for API endpoints with Redis backend",
        "language": "javascript",
        "category": "api-management",
        "tags": [
          "rate-limiting",
          "api",
          "redis",
          "performance"
        ],
        "code": "class RateLimiter {\n  constructor(options) {\n    // Rate limiting logic\n  }\n}",
        "author": "DevOps Team",
        "version": "2.1.0",
        "lastUpdated": "2024-01-20T14:30:00Z",
        "usage": "Add to Express.js middleware for API protection",
        "dependencies": [
          "redis",
          "express"
        ],
        "examples": [
          "user_api",
          "public_api",
          "webhook_endpoints"
        ],
        "parameters": [
          {
            "name": "options",
            "type": "object",
            "description": "Configuration options for the rate limiter including limits and time windows",
            "required": true,
            "example": {
              "maxRequests": 100,
              "windowMs": 60000
            }
          },
          {
            "name": "maxRequests",
            "type": "integer",
            "description": "Maximum number of requests allowed per time window",
            "required": false,
            "default": 100,
            "min": 1,
            "max": 10000
          },
          {
            "name": "windowMs",
            "type": "integer",
            "description": "Time window in milliseconds for rate limiting",
            "required": false,
            "default": 60000,
            "min": 1000,
            "max": 3600000,
            "example": 60000
          },
          {
            "name": "skipSuccessfulRequests",
            "type": "boolean",
            "description": "Whether to skip rate limiting for successful requests",
            "required": false,
            "default": false,
            "allowedValues": [
              true,
              false
            ]
          }
        ],
        "git": "https://github.com/example/api-rate-limiter",
        "rating": 4.9,
        "downloads": 89
      },
      {
        "id": "what_do_i_do",
        "name": "what_do_i_do",
        "displayName": "What Do I Do Function",
        "description": "A placeholder function for testing and demonstration purposes",
        "type": "functions",
        "category": "utility",
        "tags": [
          "placeholder",
          "test",
          "demo"
        ],
        "author": "Developer",
        "version": "1.0.0",
        "lastUpdated": "2025-08-28T00:10:59.568073",
        "usage": "This is a placeholder function for testing the toolkit system",
        "dependencies": [],
        "examples": [
          "testing",
          "demonstration"
        ],
        "git": "",
        "rating": 5,
        "downloads": 0,
        "language": "python",
        "code": "# This is a placeholder function\ndef what_do_i_do():\n    return 'This is a test function'",
        "parameters": []
      },
      {
        "id": "data_transformer",
        "name": "data_transformer",
        "displayName": "Data Transformer",
        "description": "Flexible data transformation utility that can convert between various data formats and structures",
        "language": "python",
        "category": "data-processing",
        "tags": [
          "transformation",
          "data",
          "conversion",
          "utility"
        ],
        "code": "def transform_data(data, transformation_rules):\n    # Data transformation logic here\n    transformed = {}\n    for rule in transformation_rules:\n        # Apply transformation rules\n        pass\n    return transformed",
        "author": "Data Engineering Team",
        "version": "1.0.0",
        "lastUpdated": "2025-01-15T10:30:00Z",
        "usage": "Use for converting data between different formats and schemas",
        "dependencies": [
          "pandas",
          "numpy"
        ],
        "examples": [
          "csv_to_json",
          "schema_migration",
          "data_cleaning"
        ],
        "parameters": [
          {
            "name": "data",
            "type": "any",
            "description": "Input data to be transformed",
            "required": true
          },
          {
            "name": "transformation_rules",
            "type": "list",
            "description": "List of transformation rules to apply",
            "required": true
          }
        ],
        "git": "https://github.com/example/data-transformer",
        "rating": 4.7,
        "downloads": 78
      },
      {
        "id": "file_processor",
        "name": "file_processor",
        "displayName": "File Processor",
        "description": "Efficient file processing utility with support for multiple file formats and batch operations",
        "language": "python",
        "category": "file-management",
        "tags": [
          "file",
          "processing",
          "batch",
          "utility"
        ],
        "code": "def process_files(file_paths, processor_func):\n    results = []\n    for file_path in file_paths:\n        # Process each file\n        result = processor_func(file_path)\n        results.append(result)\n    return results",
        "author": "Backend Team",
        "version": "1.2.0",
        "lastUpdated": "2025-01-10T14:20:00Z",
        "usage": "Process multiple files in batch with custom processing logic",
        "dependencies": [
          "pathlib",
          "pandas"
        ],
        "examples": [
          "batch_csv_processing",
          "log_file_analysis",
          "image_processing"
        ],
        "parameters": [
          {
            "name": "file_paths",
            "type": "list",
            "description": "List of file paths to process",
            "required": true
          },
          {
            "name": "processor_func",
            "type": "function",
            "description": "Function to apply to each file",
            "required": true
          }
        ],
        "git": "https://github.com/example/file-processor",
        "rating": 4.6,
        "downloads": 92
      }
    ],
    "containers": [
      {
        "id": "cont_001",
        "name": "PostgreSQL Development Container",
        "description": "Ready-to-use PostgreSQL container with common development tools and extensions",
        "type": "docker",
        "category": "database",
        "tags": [
          "postgresql",
          "database",
          "development",
          "docker"
        ],
        "dockerfile": "FROM postgres:15\n# Development setup\nRUN apt-get update && apt-get install -y \\\n    postgresql-contrib \\\n    postgresql-15-postgis-3",
        "dockerCompose": "version: '3.8'\nservices:\n  postgres:\n    build: .\n    environment:\n      POSTGRES_DB: devdb\n      POSTGRES_USER: devuser",
        "author": "Infrastructure Team",
        "version": "1.2.0",
        "lastUpdated": "2024-01-18T09:15:00Z",
        "usage": "Perfect for local development and testing",
        "dependencies": [
          "docker",
          "docker-compose"
        ],
        "examples": [
          "local_dev",
          "testing",
          "ci_cd"
        ],
        "rating": 4.7,
        "downloads": 203
      },
      {
        "id": "cont_002",
        "name": "Node.js Microservice Base",
        "description": "Lightweight Node.js container optimized for microservices with health checks",
        "type": "docker",
        "category": "runtime",
        "tags": [
          "nodejs",
          "microservice",
          "health-check",
          "optimized"
        ],
        "dockerfile": "FROM node:18-alpine\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci --only=production",
        "dockerCompose": "version: '3.8'\nservices:\n  app:\n    build: .\n    ports:\n      - '3000:3000'\n    healthcheck:\n      test: ['CMD', 'curl', '-f', 'http://localhost:3000/health']",
        "author": "Backend Team",
        "version": "1.0.0",
        "lastUpdated": "2024-01-22T16:45:00Z",
        "usage": "Base image for Node.js microservices",
        "dependencies": [
          "docker"
        ],
        "examples": [
          "api_service",
          "worker_service",
          "webhook_service"
        ],
        "rating": 4.6,
        "downloads": 134
      }
    ],
    "infrastructure": [
      {
        "id": "tf_001",
        "name": "AWS VPC with Private Subnets",
        "description": "Complete VPC setup with public/private subnets, NAT gateway, and security groups",
        "provider": "aws",
        "category": "networking",
        "tags": [
          "aws",
          "vpc",
          "networking",
          "security",
          "infrastructure"
        ],
        "mainTf": "resource \"aws_vpc\" \"main\" {\n  cidr_block = var.vpc_cidr\n  \n  tags = {\n    Name = \"${var.environment}-vpc\"\n  }\n}",
        "variablesTf": "variable \"vpc_cidr\" {\n  description = \"CIDR block for VPC\"\n  type        = string\n  default     = \"10.0.0.0/16\"\n}",
        "outputsTf": "output \"vpc_id\" {\n  value = aws_vpc.main.id\n}",
        "author": "Cloud Team",
        "version": "2.0.0",
        "lastUpdated": "2024-01-19T11:20:00Z",
        "usage": "Deploy secure VPC infrastructure for production workloads",
        "dependencies": [
          "terraform",
          "aws_provider"
        ],
        "examples": [
          "production_env",
          "staging_env",
          "multi_az_setup"
        ],
        "rating": 4.9,
        "downloads": 312
      },
      {
        "id": "tf_002",
        "name": "Kubernetes Cluster on GCP",
        "description": "Production-ready GKE cluster with node pools, monitoring, and logging",
        "provider": "gcp",
        "category": "kubernetes",
        "tags": [
          "gcp",
          "kubernetes",
          "gke",
          "monitoring",
          "infrastructure"
        ],
        "mainTf": "resource \"google_container_cluster\" \"primary\" {\n  name     = var.cluster_name\n  location = var.region\n  \n  node_config {\n    machine_type = var.machine_type\n  }\n}",
        "variablesTf": "variable \"cluster_name\" {\n  description = \"Name of the GKE cluster\"\n  type        = string\n}",
        "outputsTf": "output \"cluster_endpoint\" {\n  value = google_container_cluster.primary.endpoint\n}",
        "author": "Platform Team",
        "version": "1.5.0",
        "lastUpdated": "2024-01-21T13:10:00Z",
        "usage": "Deploy managed Kubernetes clusters on Google Cloud",
        "dependencies": [
          "terraform",
          "google_provider"
        ],
        "examples": [
          "production_cluster",
          "development_cluster",
          "multi_region"
        ],
        "rating": 4.8,
        "downloads": 178
      }
    ]
  },
  "categories": {
    "data-processing": "Data manipulation, validation, and processing utilities",
    "api-management": "API development, testing, and management tools",
    "file-management": "File processing, manipulation, and management utilities",
    "utility": "General utility functions and helpers",
    "database": "Database containers, scripts, and utilities",
    "runtime": "Application runtime environments and base images",
    "networking": "Network infrastructure and security configurations",
    "kubernetes": "Kubernetes manifests, operators, and configurations"
  },
  "tags": [
    "python",
    "javascript",
    "docker",
    "infrastructure",
    "aws",
    "gcp",
    "kubernetes",
    "validation",
    "api",
    "database",
    "microservice",
    "networking",
    "security",
    "monitoring",
    "development",
    "production",
    "testing",
    "ci_cd"
  ]
}